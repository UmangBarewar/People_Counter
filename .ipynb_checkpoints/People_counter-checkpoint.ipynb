{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39abe32-0637-4ed5-9bb3-ee87ed10cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1396b4-493e-40bd-b53f-021c5f2bdd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=YOLO(\"../Running Yolo/yolov8l.pt\")\n",
    "# DOWNLOAD YOLO MODEL ACCORDING TO YOUR HARDWARE CAPABILITIES . this is a large model running on GPU, you can run on it CPU but nano model is best suited \n",
    "#for CPU\n",
    "coco_classes = [\n",
    "    \"Person\", \"Bicycle\", \"Car\", \"Motorcycle\", \"Airplane\", \"Bus\", \"Train\", \"Truck\", \"Boat\", \"Traffic light\",\n",
    "    \"Fire hydrant\", \"Stop sign\", \"Parking meter\", \"Bench\", \"Bird\", \"Cat\", \"Dog\", \"Horse\", \"Sheep\", \"Cow\",\n",
    "    \"Elephant\", \"Bear\", \"Zebra\", \"Giraffe\", \"Backpack\", \"Umbrella\", \"Handbag\", \"Tie\", \"Suitcase\", \"Frisbee\",\n",
    "    \"Skis\", \"Snowboard\", \"Sports ball\", \"Kite\", \"Baseball bat\", \"Baseball glove\", \"Skateboard\", \"Surfboard\",\n",
    "    \"Tennis racket\", \"Bottle\", \"Wine glass\", \"Cup\", \"Fork\", \"Knife\", \"Spoon\", \"Bowl\", \"Banana\", \"Apple\",\n",
    "    \"Sandwich\", \"Orange\", \"Broccoli\", \"Carrot\", \"Hot dog\", \"Pizza\", \"Donut\", \"Cake\", \"Chair\", \"Couch\",\n",
    "    \"Potted plant\", \"Bed\", \"Dining table\", \"Toilet\", \"TV\", \"Laptop\", \"Mouse\", \"Remote\", \"Keyboard\",\n",
    "    \"Cell phone\", \"Microwave\", \"Oven\", \"Toaster\", \"Sink\", \"Refrigerator\", \"Book\", \"Clock\", \"Vase\", \"Scissors\",\n",
    "    \"Teddy bear\", \"Hair drier\", \"Toothbrush\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45dd1829-e471-4067-ac5a-774afcb3295e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "Current device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device (GPU)\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    # Use CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU\")\n",
    "\n",
    "print(\"Current device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22bce66a-2efd-4d3e-8404-78b1c954b583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: D:\\Conda_Pro_\\Objectdetection\\People Counter\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e861e-12a5-4da5-8e71-d07a574ea092",
   "metadata": {},
   "source": [
    "## For putting a tracker \n",
    "We will be using a tracker from github repository: https://github.com/abewley/sort/blob/master/sort.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8b2117-1c34-409a-bbd3-66e01cb862da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sort import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316aa76b-0760-4ff4-9397-e777dab19ca7",
   "metadata": {},
   "source": [
    "## The limits up-down have been made according to the stock footage. \n",
    "I wanted to count to people going up and down so I made limits up & down giving the coordinates of the lines which act as the counter of people.\n",
    "You may need to change this according to the footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2466d301-a71b-48df-8481-a212e8df24ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracker\n",
    "tracker = Sort(max_age=1, min_hits=3, iou_threshold=0.3)\n",
    "limitsUp =[103,161,296,161]\n",
    "limitsDown =[527,489,735,489]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e88154e-e84e-4556-9d83-a6c1bd4eda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.imread(\"mask.png\",cv2.IMREAD_GRAYSCALE)\n",
    "mask = mask.astype(np.uint8)\n",
    "# this mask is again made specifically for the stock footage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f061205-e3a2-4aaa-9039-305e13fcf01b",
   "metadata": {},
   "source": [
    "## Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c9311b-2e77-4115-b865-294772224e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 71.1ms\n",
      "Speed: 5.0ms preprocess, 71.1ms inference, 193.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[        402         646         525         719           2]\n",
      "[        234         320         353         580           1]\n",
      "\n",
      "0: 384x640 2 persons, 51.1ms\n",
      "Speed: 3.0ms preprocess, 51.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[        402         646         525         719           2]\n",
      "[        234         320         353         580           1]\n",
      "\n",
      "0: 384x640 2 persons, 50.8ms\n",
      "Speed: 1.9ms preprocess, 50.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     401.14       643.4      527.74      718.78           2]\n",
      "[     232.23      317.09      351.95       578.2           1]\n",
      "\n",
      "0: 384x640 2 persons, 51.8ms\n",
      "Speed: 2.0ms preprocess, 51.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     401.14         640      530.61      718.29           2]\n",
      "[     230.33      313.78      350.81       575.6           1]\n",
      "\n",
      "0: 384x640 2 persons, 50.5ms\n",
      "Speed: 2.0ms preprocess, 50.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     399.42      636.96      531.45      718.08           2]\n",
      "[     228.21      310.83      349.11      573.28           1]\n",
      "\n",
      "0: 384x640 2 persons, 51.1ms\n",
      "Speed: 2.5ms preprocess, 51.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     397.89      634.06      531.88      717.91           2]\n",
      "[     227.01      308.39      348.53      571.37           1]\n",
      "\n",
      "0: 384x640 2 persons, 50.6ms\n",
      "Speed: 2.0ms preprocess, 50.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[      396.6       630.6      532.77      717.64           2]\n",
      "[      225.4      305.12      347.55      567.72           1]\n",
      "\n",
      "0: 384x640 2 persons, 51.2ms\n",
      "Speed: 2.0ms preprocess, 51.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[      394.3      627.53      531.41      717.46           2]\n",
      "[     223.56      302.87      346.52      565.68           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.2ms\n",
      "Speed: 2.0ms preprocess, 51.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[      392.1      624.03      530.24      717.19           2]\n",
      "[     222.01      300.77       345.1      563.05           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.9ms\n",
      "Speed: 1.0ms preprocess, 51.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     386.37      621.51      517.81      716.45           2]\n",
      "[     220.15      298.02      343.28      559.55           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.2ms\n",
      "Speed: 2.1ms preprocess, 51.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     384.85       618.9      510.68      715.98           2]\n",
      "[     218.68      295.79      341.49      556.32           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.4ms\n",
      "Speed: 2.1ms preprocess, 51.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     384.38      615.79      504.75       715.4           2]\n",
      "[     217.57      294.06      340.17      554.22           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.6ms\n",
      "Speed: 2.0ms preprocess, 51.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     345.62     0.60828      397.18      59.608           3]\n",
      "[     383.85      612.74      500.39      715.21           2]\n",
      "[     216.57      290.92      339.04      550.82           1]\n",
      "\n",
      "0: 384x640 3 persons, 50.7ms\n",
      "Speed: 5.0ms preprocess, 50.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     346.82     0.52537      399.77      61.504           3]\n",
      "[     384.36      609.08      499.53      715.13           2]\n",
      "[     215.62       287.9      337.99      547.61           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     347.68     0.61363      401.44      63.363           3]\n",
      "[     384.95      606.05      500.29      715.55           2]\n",
      "[     214.18      285.52      336.78      545.18           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     348.65     0.67054      403.32      65.294           3]\n",
      "[     383.17      603.18      496.13      715.59           2]\n",
      "[     212.82      283.29      335.27      542.51           1]\n",
      "\n",
      "0: 384x640 3 persons, 50.0ms\n",
      "Speed: 3.0ms preprocess, 50.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     348.95     0.70716      404.58      67.257           3]\n",
      "[     381.91      599.33      492.64      715.19           2]\n",
      "[      211.2      279.51      333.92      540.01           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.7ms\n",
      "Speed: 2.1ms preprocess, 51.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[      349.2     0.67613      406.14      69.292           3]\n",
      "[     380.91      595.36      490.66      715.04           2]\n",
      "[     210.11      276.14      333.33      537.91           1]\n",
      "\n",
      "0: 384x640 3 persons, 50.9ms\n",
      "Speed: 2.0ms preprocess, 50.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     349.75     0.54531       407.5      70.749           3]\n",
      "[     380.48      591.77      490.09      715.22           2]\n",
      "[     208.83      273.66      332.11      536.55           1]\n",
      "\n",
      "0: 384x640 3 persons, 50.3ms\n",
      "Speed: 1.0ms preprocess, 50.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     350.12     0.51829      409.08       72.53           3]\n",
      "[     378.43      589.43      486.64      715.73           2]\n",
      "[     207.26      270.26      330.85      533.42           1]\n",
      "\n",
      "0: 384x640 4 persons, 50.7ms\n",
      "Speed: 2.0ms preprocess, 50.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     350.17     0.72339      410.32      74.908           3]\n",
      "[     377.13      587.17      484.01       716.1           2]\n",
      "[     206.02      267.36       329.8       530.1           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.2ms\n",
      "Speed: 1.0ms preprocess, 51.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     350.83      0.6047      412.06      76.585           3]\n",
      "[     376.74      584.06      482.38      715.99           2]\n",
      "[     204.91      264.94      328.81      527.07           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.8ms\n",
      "Speed: 1.0ms preprocess, 51.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     351.56     0.45255      413.47      77.911           3]\n",
      "[      375.1      581.43      480.11      716.19           2]\n",
      "[     204.15      261.83      327.56      523.72           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.4ms\n",
      "Speed: 3.0ms preprocess, 51.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     352.53     0.30324      415.21      79.095           3]\n",
      "[     373.79      578.15      478.08      716.03           2]\n",
      "[     203.14      259.02      325.93      520.98           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.3ms\n",
      "Speed: 2.1ms preprocess, 51.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     354.06     0.38513      417.26      80.657           3]\n",
      "[     373.32      575.49      476.76      716.18           2]\n",
      "[      202.9      255.98      325.25      518.84           1]\n",
      "\n",
      "0: 384x640 3 persons, 50.9ms\n",
      "Speed: 1.5ms preprocess, 50.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     354.98     0.73544      418.26       82.84           3]\n",
      "[     372.51      572.66      475.04      716.21           2]\n",
      "[     202.75      253.75      324.48      516.67           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.1ms\n",
      "Speed: 2.0ms preprocess, 51.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     355.77     0.74648      418.77      84.382           3]\n",
      "[     371.59      570.22      473.15      716.38           2]\n",
      "[     202.19      251.21      323.46      514.45           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.1ms\n",
      "Speed: 3.0ms preprocess, 51.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     356.74      0.8382      419.52      86.129           3]\n",
      "[     370.33         567      471.49      716.22           2]\n",
      "[      201.9      248.05      322.57      512.06           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.4ms\n",
      "Speed: 1.0ms preprocess, 51.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     357.77     0.93896      420.38      87.975           3]\n",
      "[     369.33      564.35      470.18      716.37           2]\n",
      "[     201.27      244.38      321.52      509.23           1]\n",
      "\n",
      "0: 384x640 3 persons, 50.5ms\n",
      "Speed: 2.0ms preprocess, 50.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[      359.3     0.85981      421.46      89.385           3]\n",
      "[     369.06      561.52      469.68       716.4           2]\n",
      "[     200.96      242.29       320.6      507.72           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.4ms\n",
      "Speed: 3.0ms preprocess, 51.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     360.77     0.71302      422.87      90.632           3]\n",
      "[     368.22      559.07      468.37      716.57           2]\n",
      "[     200.32      238.86      319.53      504.73           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.1ms\n",
      "Speed: 1.8ms preprocess, 51.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     361.31     0.77144      423.35      92.241           3]\n",
      "[     367.48      556.86      466.43      716.71           2]\n",
      "[     199.54      236.08      318.42      501.99           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     362.61     0.90013      424.32      93.997           3]\n",
      "[     366.16      554.06      464.21       716.2           2]\n",
      "[     198.03       233.8      316.67      499.73           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.7ms\n",
      "Speed: 1.0ms preprocess, 51.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     363.32     0.99802      425.06      95.865           3]\n",
      "[     365.01         551      462.16      716.14           2]\n",
      "[     197.06      231.51      315.81      497.21           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.6ms\n",
      "Speed: 3.0ms preprocess, 51.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[      364.2      1.0826      425.96      97.777           3]\n",
      "[     363.66      547.94      460.42      716.15           2]\n",
      "[     195.87      228.36      314.42      494.14           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.0ms\n",
      "Speed: 2.5ms preprocess, 51.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     365.16      1.1511      426.92      99.716           3]\n",
      "[     360.17      544.74      458.92      716.32           2]\n",
      "[     194.84      225.09      313.23      490.65           1]\n",
      "\n",
      "0: 384x640 3 persons, 51.5ms\n",
      "Speed: 2.0ms preprocess, 51.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     366.33     0.99725      428.37      101.23           3]\n",
      "[      354.9      541.54      456.51      716.52           2]\n",
      "[     193.85      222.86      312.14      488.54           1]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"people.mp4\")  # For Video\n",
    " \n",
    "totalCountUp = []\n",
    "totalCountDown = []\n",
    " \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break  # Break the loop if there are no more frames\n",
    "    \n",
    "    # Apply the mask to the frame\n",
    "    masked_frame = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    # Process results\n",
    " \n",
    "    imgGraphics = cv2.imread(\"graphics.png\", cv2.IMREAD_UNCHANGED)\n",
    "    img = cvzone.overlayPNG(img, imgGraphics, (730, 260))\n",
    "    results = model(masked_frame, stream=True)\n",
    " \n",
    "    detections = np.empty((0, 5))\n",
    " \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Bounding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            # cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,255),3)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    " \n",
    "            # Confidence\n",
    "            conf = math.ceil((box.conf[0] * 100)) / 100\n",
    "            # Class Name\n",
    "            cls = int(box.cls[0])\n",
    "            # currentClass = coco_classes[cls]\n",
    " \n",
    "            if coco_classes[cls] == \"Person\" and conf > 0.3:\n",
    "                # cvzone.putTextRect(img, f'{currentClass} {conf}', (max(0, x1), max(35, y1)),\n",
    "                #                    scale=0.6, thickness=1, offset=3)\n",
    "                # cvzone.cornerRect(img, (x1, y1, w, h), l=9, rt=5)\n",
    "                currentArray = np.array([x1, y1, x2, y2, conf])\n",
    "                detections = np.vstack((detections, currentArray))\n",
    " \n",
    "    resultsTracker = tracker.update(detections)\n",
    " \n",
    "    cv2.line(img, (limitsUp[0], limitsUp[1]), (limitsUp[2], limitsUp[3]), (0, 0, 255), 5)\n",
    "    cv2.line(img, (limitsDown[0], limitsDown[1]), (limitsDown[2], limitsDown[3]), (0, 0, 255), 5)\n",
    "    for result in resultsTracker:\n",
    "        x1, y1, x2, y2, id = result\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        print(result)\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        cvzone.cornerRect(img, (x1, y1, w, h), l=9, rt=2, colorR=(255, 0, 255))\n",
    "        cvzone.putTextRect(img, f' {int(id)}', (max(0, x1), max(35, y1)),\n",
    "                           scale=2, thickness=3, offset=10)\n",
    " \n",
    "        cx, cy = x1 + w // 2, y1 + h // 2\n",
    "        cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "        # for people going up\n",
    "        if limitsUp[0] < cx < limitsUp[2] and limitsUp[1] - 15 < cy < limitsUp[1] + 15:\n",
    "            if totalCountUp.count(id) == 0:\n",
    "                totalCountUp.append(id)\n",
    "                cv2.line(img, (limitsUp[0], limitsUp[1]), (limitsUp[2], limitsUp[3]), (0, 255, 0), 5)\n",
    "         # for people going down\n",
    "        if limitsDown[0] < cx < limitsDown[2] and limitsDown[1] - 15 < cy < limitsDown[1] + 15:\n",
    "            if totalCountDown.count(id) == 0:\n",
    "                totalCountDown.append(id)\n",
    "                cv2.line(img, (limitsDown[0], limitsDown[1]), (limitsDown[2], limitsDown[3]), (0, 255, 0), 5)\n",
    "         \n",
    "    # cvzone.putTextRect(img, f' Count: {len(totalCount)}', (50, 50))\n",
    "    cv2.putText(img,str(len(totalCountUp)),(929,345),cv2.FONT_HERSHEY_PLAIN,5,(139,195,75),7)\n",
    "    cv2.putText(img,str(len(totalCountDown)),(1191,345),cv2.FONT_HERSHEY_PLAIN,5,(50,50,230),7)\n",
    " \n",
    "    cv2.imshow(\"Image\", img)\n",
    "    # cv2.imshow(\"ImageRegion\", imgRegion)\n",
    "\n",
    " # Wait for key press (display frame for 1 millisecond)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit , waitKey os kept 0 , so we can move\n",
    "        #frame by frame\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb74ef8-146a-4f13-8f4a-b8b1f05c4e1f",
   "metadata": {},
   "source": [
    "## THE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eae818-56de-4547-8c8c-6ec485e32b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
